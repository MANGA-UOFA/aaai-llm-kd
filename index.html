<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Conference Tutorial</title>
  <style>
    body {
      font-family: 'Helvetica Neue', sans-serif;
      margin: 0;
      padding: 0;
      background-color: #f9f9f9;
      color: #333;
    }

    header {
      text-align: center;
      padding: 4rem 1rem 2rem;
      background-color: #fff;
      border-bottom: 1px solid #eee;
    }

    header h1 {
      margin: 0;
      font-size: 2.5rem;
    }

    section {
      max-width: 1200px;
      margin: 0 auto;
      padding: 2rem 1rem;
    }

    .abstract {
      background-color: #fff;
      border: 1px solid #ddd;
      border-radius: 8px;
      padding: 2rem;
      box-shadow: 0 2px 6px rgba(0, 0, 0, 0.03);
      margin-bottom: 2rem;
    }

    .abstract h2 {
      margin-top: 0;
      font-size: 1.5rem;
    }

    .speakers {
      display: flex;
      flex-wrap: wrap;
      justify-content: center;
      gap: 2rem;
      margin-bottom: 3rem;
    }

    .speaker {
      background-color: #fff;
      border: 1px solid #ddd;
      border-radius: 8px;
      max-width: 300px;
      text-align: center;
      padding: 1.5rem;
      box-shadow: 0 2px 6px rgba(0, 0, 0, 0.05);
    }

    .speaker img {
      width: 100px;
      height: 100px;
      object-fit: cover;
      border-radius: 50%;
      margin-bottom: 1rem;
    }

    .speaker h2 {
      margin: 0.5rem 0 0.25rem;
      font-size: 1.2rem;
    }

    .speaker p {
      font-size: 0.95rem;
      color: #555;
    }

    .resources {
      background-color: #fff;
      border: 1px solid #ddd;
      border-radius: 8px;
      padding: 2rem;
      box-shadow: 0 2px 6px rgba(0, 0, 0, 0.03);
    }

    .resources h2 {
      margin-top: 0;
      font-size: 1.5rem;
    }

    .resources ul {
      list-style: none;
      padding-left: 0;
    }

    .resources li {
      margin-bottom: 0.5rem;
    }

    .resources a {
      color: #0077cc;
      text-decoration: none;
    }

    .resources a:hover {
      text-decoration: underline;
    }

    @media (max-width: 768px) {
      .speakers {
        flex-direction: column;
        align-items: center;
      }
    }
  </style>
</head>
<body>

  <header>
    <h1>AAAI'26 Tutorial<br> Knowledge Distillation for Language Models:<br> Challenges and Opportunities with Sequential Data</h1>
  </header>

  <section class="abstract">
    <h2>Tutorial Abstract</h2>
    <p>
      Knowledge distillation (KD) is a technique that transfers the knowledge from a teacher model to a student model, where the teacher is usually larger and more powerful.
      In this tutorial, we will briefly introduce the basic concepts, including intermediate-layer matching and prediction-matching KD.
      We then dive into the challenges and opportunities of KD with sequential data, which lead to advanced techniques such as reinforcement learning KD and multi-teacher KD.
      We will also cover practical KD applications such as LLM sequence compression and LLM self-distillation.
      The goal of this tutorial is to provide participants with a comprehensive understanding of the techniques and applications of KD for language models.
    </p>

    <p>
      <strong>Location</strong>: TBA
    </p>

    <p>
      <strong>Time</strong>: TBA
    </p>


  </section>

  <section class="speakers">
    <div class="speaker">
      <img src="assets/yuqiao_headshot.jpg" alt="Speaker 1">
      <h2>Yuqiao Wen</h2>
      <p>
        Yuqiao is currently a third-year PhD student at the Department of Computing Science, University of Alberta, after having his MSc in 2022 and BSc in 2020.
        Yuqiao's research lies in developing efficient methods for large language models and making them more accessible for everyone;
        he has a focus on machine learning problems in knowledge distillation such as label bias and exposure bias.
        He has published a number of papers at top-tier venues such as AAAI, ACL, and ICLR, including one winning an Area Chair's Award.
        He was a co-presenter of a three-hour tutorial at the Amii Upper Bound Conference.
      </p>
    </div>

    <div class="speaker">
      <img src="https://cs.uwaterloo.ca/~fhs/static/img/freda-02.jpg" alt="Speaker 2">
      <h2>Freda Shi</h2>
      <p>
        Freda is a second-year Assistant Professor in the David R. Cheriton School of Computer Science at the University of Waterloo and a Faculty Member at the Vector Institute.
        Her research interests are in computational linguistics, natural language processing, and cognitive sciences.
        She has been working on knowledge distillation for syntactic analysis and multilingualism, with relevant papers published at ACL and ICLR.
        Her work has been recognized with a Google PhD Fellowship, a Facebook Fellowship Finalist Award, and Best Paper Nominations at ACL 2019, 2021, and 2024.
        She has served as an Area Chair for conferences such as ACL, EMNLP, and COLM, and as a program committee member or a reviewer for leading journals and conferences in computational linguistics and machine learning, including TACL, TPAMI, ACL, COLING, EMNLP, NAACL, ICLR, ICML, and NeurIPS.
      </p>
      <p>
      </p>
    </div>

    <div class="speaker">
      <img src="assets/lili_headshot.png" alt="Speaker 3">
      <h2>Lili Mou</h2>
      <p>
        Lili is an Associate Professor at the Department of Computing Science, University of Alberta.
        His main research interest lies in developing novel machine learning methods for NLP tasks;
        successful examples include tree-based convolutional neural networks, edit-based unsupervised text generation, and an ensemble-then-distill framework for multi-teacher KD.
        He regularly serves as a Senior Program Committee Member or an Area Chair for AI and NLP conferences, and is an Action Editor for ACL Rolling Review.
        He is an Amii Fellow and a Canada CIFAR AI Chair, and has received a AAAI New Faculty Highlight Award; he also received an ACL Best Paper Nomination (2019) and ACL Area Chair's Award (2024).
        Lili has been a co-organizer of the Workshop on Efficient Speech and Natural Language Processing, co-located with NeurIPS during 2021--2023.
        He presented multiple conference tutorials at EMNLP-IJCNLP'19, ACL'20, and NAACL'25.
      </p>
    </div>
  </section>

  <section class="resources">
    <h2>Presentation & Resources</h2>
    <ul>
      <li><a href="assets/LLMKD-full-AAAI.pdf" target="_blank">Slides</a></li>
      <!-- <li><a href="https://example.com/demo" target="_blank">Live Demo Application</a></li>
      <li><a href="https://github.com/example/repo" target="_blank">GitHub Repository</a></li> -->
    </ul>
  </section>

</body>
</html>
